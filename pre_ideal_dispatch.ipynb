{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from datetime import date, datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyomo.environ as pyo\n",
    "from thefuzz import process, fuzz\n",
    "\n",
    "import sys\n",
    "\n",
    "from app.utils.misc import save_file, PARAMS as files_to_download\n",
    "from app.model import UnitCommitmentModel, DispatchOptions, DispatchConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DispatchConfig(\n",
    "    dispatch_type=\"bess_preideal\"\n",
    "    # dispatch_type=\"ideal\"\n",
    "    # dispatch_type=\"preideal\"\n",
    ")\n",
    "# DISPATCH_DATE = date(2024,4,18)\n",
    "\n",
    "# Fechas mucha termica\n",
    "# DISPATCH_DATE = date(2024,3,23)\n",
    "# DISPATCH_DATE = date(2024,3,24)\n",
    "# DISPATCH_DATE = date(2024,3,25)\n",
    "# DISPATCH_DATE = date(2024,3,26)\n",
    "# DISPATCH_DATE = date(2024,3,27)\n",
    "# DISPATCH_DATE = date(2024,3,28)\n",
    "# DISPATCH_DATE = date(2024,3,29)\n",
    "# DISPATCH_DATE = date(2024,3,30)\n",
    "\n",
    "\n",
    "# DISPATCH_DATE = date(2024,4,15)\n",
    "# DISPATCH_DATE = date(2024,4,16)\n",
    "# DISPATCH_DATE = date(2024,4,17)\n",
    "DISPATCH_DATE = date(2024, 4, 18)\n",
    "# DISPATCH_DATE = date(2024,4,19)\n",
    "# DISPATCH_DATE = date(2024,4,20)\n",
    "# DISPATCH_DATE = date(2024,4,21)\n",
    "# DISPATCH_DATE = date(2024,4,22)\n",
    "\n",
    "\n",
    "# DISPATCH_DATE = date(2024,4,15)\n",
    "# DISPATCH_DATE = date(2024,4,16)\n",
    "# DISPATCH_DATE = date(2024,3,23)\n",
    "\n",
    "# DISPATCH_DATE = date(2024,4,18)\n",
    "# DISPATCH_DATE = date(2024,4,19)\n",
    "# DISPATCH_DATE = date(2024,4,22)\n",
    "# DISPATCH_DATE = date(2024,4,25) # -> despachan a CALIMA todo el día aunque los precios no son bajos\n",
    "\n",
    "# Mucha hidro\n",
    "# DISPATCH_DATE = date(2024,5,5)\n",
    "# DISPATCH_DATE = date(2024,5,6)\n",
    "# DISPATCH_DATE = date(2024,5,7)\n",
    "\n",
    "# Promedio\n",
    "# DISPATCH_DATE = date(2024,9,5)\n",
    "# DISPATCH_DATE = date(2024,9,6)\n",
    "# DISPATCH_DATE = date(2024,9,7)\n",
    "# DISPATCH_DATE = date(2024,10,3)\n",
    "\n",
    "\n",
    "# Al azar\n",
    "# DISPATCH_DATE = date(2024,8,10)\n",
    "# DISPATCH_DATE = date(2024,3,23)\n",
    "# DISPATCH_DATE = date(2024,5,25)\n",
    "# DISPATCH_DATE = date(2024,6,9)\n",
    "CHECK_FOLDER = Path(f\"data/{DISPATCH_DATE}\")\n",
    "if CHECK_FOLDER.is_dir() and CHECK_FOLDER.exists():\n",
    "    print(\"... files already downloaded. Skipping download\")\n",
    "else:\n",
    "    for file in files_to_download.keys():\n",
    "        save_file(file_type=file, file_date=DISPATCH_DATE)\n",
    "\n",
    "\n",
    "price_pattern = r\"P(\\d+)\"\n",
    "dispo_pattern = r\"DISCONF(\\d+)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dispatch_type == \"ideal\":\n",
    "    dispo_come = pd.read_csv(\n",
    "        \"data/DispoCome_resource.csv\", parse_dates=[\"datetime\"], engine=\"pyarrow\"\n",
    "    )\n",
    "dispo = pd.read_csv(\n",
    "    \"data/dispo_declarada.csv\", parse_dates=[\"datetime\"], engine=\"pyarrow\"\n",
    ")\n",
    "ofertas = pd.read_csv(\"data/ofertas.csv\", parse_dates=[\"Date\"], engine=\"pyarrow\")\n",
    "demanda = pd.read_csv(\"data/demaCome.csv\", parse_dates=[\"datetime\"], engine=\"pyarrow\")\n",
    "agc_asignado = pd.read_csv(\n",
    "    \"data/agc_asignado.csv\", parse_dates=[\"datetime\"], engine=\"pyarrow\"\n",
    ")\n",
    "parametros_plantas = pd.read_csv(\"data/parametros_plantas.csv\")\n",
    "\n",
    "# Precio bolsa\n",
    "precio_bolsa = pd.read_csv(\n",
    "    \"data/precio_bolsa/precio_bolsa_2024.csv\",\n",
    "    parse_dates=[\"datetime\"],\n",
    "    engine=\"pyarrow\",\n",
    ")\n",
    "precio_bolsa[\"precio_bolsa\"] = precio_bolsa[\"precio_bolsa\"] * 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "MO = []\n",
    "CC = {}\n",
    "cc_price = {}\n",
    "cc_dispo = {}\n",
    "prices = {}\n",
    "with open(\n",
    "    f\"data/{DISPATCH_DATE}/OFEI{DISPATCH_DATE.month:0>2}{DISPATCH_DATE.day:0>2}.txt\",\n",
    "    \"r\",\n",
    ") as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if \"PAP\" in line:\n",
    "            output.append(line)\n",
    "        if \"MO\" in line:\n",
    "            mo_line = line.split(\",\")\n",
    "            if len(mo_line) > 2 and \"MO\" in mo_line[1]:\n",
    "                MO.append(mo_line)\n",
    "        if (conf := re.findall(price_pattern, line)) and \"CC\" in line:\n",
    "            fline = line.split(\",\")\n",
    "            cc_price[f\"{fline[0].strip()}_{conf[0]}\"] = float(fline[2])\n",
    "            if CC.get(fline[0].strip()):\n",
    "                CC[fline[0].strip()].append(f\"{fline[0].strip()}_{conf[0]}\")\n",
    "            else:\n",
    "                CC[fline[0].strip()] = [f\"{fline[0].strip()}_{conf[0]}\"]\n",
    "        # Disponibilidad CC\n",
    "        if (conf := re.findall(dispo_pattern, line)) and \"CC\" in line:\n",
    "            fline = line.split(\",\")\n",
    "            cc_dispo[f\"{fline[0].strip()}_{conf[0]}\"] = [\n",
    "                int(disp) for disp in fline[2:]\n",
    "            ]\n",
    "\n",
    "        # Extract prices\n",
    "        if \"P\" in line:\n",
    "            pri = line.split(\",\")\n",
    "            if (\n",
    "                len(pri) == 3\n",
    "                and \" P\" in pri[1]\n",
    "                and \"u\" not in pri[1].lower()\n",
    "                and \"a\" not in pri[1].lower()\n",
    "            ):\n",
    "                prices[pri[0]] = float(pri[2]) * 1e-3\n",
    "\n",
    "\n",
    "precio_arranque = pd.DataFrame(\n",
    "    [line.split(\",\") for line in output if \"usd\" not in line.lower()],\n",
    "    columns=[\"resource\", \"type\", \"price\"],\n",
    ")\n",
    "precio_arranque[\"price\"] = precio_arranque[\"price\"].astype(float)\n",
    "\n",
    "# Minimo operativo\n",
    "minimo_operativo = pd.DataFrame(\n",
    "    MO,\n",
    "    columns=[\n",
    "        \"resource\",\n",
    "        \"type\",\n",
    "    ]\n",
    "    + list(range(24)),\n",
    ")\n",
    "minimo_operativo = (\n",
    "    minimo_operativo.set_index([\"resource\", \"type\"]).stack().reset_index()\n",
    ")\n",
    "minimo_operativo.columns = [\"resource\", \"type\", \"hour\", \"minimo_operativo\"]\n",
    "minimo_operativo[\"datetime\"] = pd.to_datetime(DISPATCH_DATE) + pd.to_timedelta(\n",
    "    minimo_operativo[\"hour\"], unit=\"h\"\n",
    ")\n",
    "minimo_operativo[\"minimo_operativo\"] = minimo_operativo[\"minimo_operativo\"].astype(\n",
    "    float\n",
    ")\n",
    "minimo_operativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Filter data by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispo = dispo[\n",
    "    (dispo.datetime.dt.date == DISPATCH_DATE) & (dispo[\"resource_name\"].notnull())\n",
    "]\n",
    "dispo = dispo.drop_duplicates(subset=[\"resource_name\", \"datetime\"])\n",
    "\n",
    "ofertas = ofertas[ofertas.Date.dt.date == DISPATCH_DATE]\n",
    "agc_asignado = agc_asignado[agc_asignado[\"datetime\"].dt.date == DISPATCH_DATE]\n",
    "demanda = demanda[demanda[\"datetime\"].dt.date == DISPATCH_DATE]\n",
    "precio_bolsa = precio_bolsa[precio_bolsa[\"datetime\"].dt.date == DISPATCH_DATE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dispatch_type == \"ideal\":\n",
    "    dispo_come = dispo_come[\n",
    "        (dispo_come.datetime.dt.date == DISPATCH_DATE)\n",
    "        & (dispo_come[\"resource_name\"].notnull())\n",
    "    ]\n",
    "    dispo_come = dispo_come.drop_duplicates(subset=[\"resource_name\", \"datetime\"])\n",
    "    for gen in dispo[\"resource_name\"].unique():\n",
    "        if gen in dispo_come[\"resource_name\"].unique():\n",
    "            serie = dispo_come[(dispo_come[\"resource_name\"] == gen)]\n",
    "            serie = (\n",
    "                serie.set_index(\"datetime\")\n",
    "                .reindex(\n",
    "                    pd.date_range(\n",
    "                        start=DISPATCH_DATE,\n",
    "                        end=DISPATCH_DATE + pd.Timedelta(days=1),\n",
    "                        freq=\"1h\",\n",
    "                        inclusive=\"left\",\n",
    "                    )\n",
    "                )\n",
    "                .fillna(0)\n",
    "            )\n",
    "            dispo.loc[dispo[\"resource_name\"] == gen, \"dispo\"] = serie[\"dispo\"].values\n",
    "        else:\n",
    "            print(\n",
    "                f\"no existe el generador {gen} en disponibilidad comercial para el {DISPATCH_DATE}. Se asignará en 0\"\n",
    "            )\n",
    "            dispo.loc[dispo[\"resource_name\"] == gen, \"dispo\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Extract prices from OFEI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1. Map names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_bid_map = {\n",
    "    gen: process.extractOne(\n",
    "        query=gen.lower(),\n",
    "        choices=dispo[\"resource_name\"].unique(),\n",
    "        scorer=fuzz.token_sort_ratio,\n",
    "        processor=lambda x: x.lower().replace(\" \", \"\"),\n",
    "        score_cutoff=70,\n",
    "    )[0]\n",
    "    for gen in prices.keys()\n",
    "}\n",
    "prices = {price_bid_map[gen]: price for gen, price in prices.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2. Transform bids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ofertas[\"Value\"] = ofertas.apply(\n",
    "    lambda x: prices.get(x[\"resource_name\"], float(x[\"Value\"])), axis=1\n",
    ")\n",
    "ofertas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ofertas.loc[ofertas[\"resource_name\"].str.contains(\"TEBSA\"),\"Value\"] = 500.000\n",
    "# ofertas[ofertas[\"resource_name\"].str.contains(\"TEBSA\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# dispo.loc[dispo[\"resource_name\"].str.contains(\"VALLE\"),\"dispo\"] = np.array([239,  1,  1,  1,  1,  1,  1,  1,  1,  1,  239,  239,  239,  239,  239,  239,  239,  239,  239,  239,  239,  239,  239,  239])*1E3\n",
    "# ofertas.loc[ofertas[\"resource_name\"].str.contains(\"VALLE\"),\"Value\"] = 500.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ofertas.loc[ofertas[\"resource_name\"].str.contains(\"TEBSA\"),\"Value\"] = 1514.537"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ofertas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Get Initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Initial condition by plant and Units\n",
    "with open(\n",
    "    f\"data//{DISPATCH_DATE}/dCondIniP{DISPATCH_DATE.month:0>2}{DISPATCH_DATE.day:0>2}.txt\",\n",
    "    \"r\",\n",
    ") as file:\n",
    "    data = file.readlines()\n",
    "    data = [line.strip().split(\",\") for line in data]\n",
    "    headers = data.pop(0)\n",
    "condicion_inicial_planta = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "with open(\n",
    "    f\"data/{DISPATCH_DATE}/dCondIniU{DISPATCH_DATE.month:0>2}{DISPATCH_DATE.day:0>2}.txt\",\n",
    "    \"r\",\n",
    ") as file:\n",
    "    data = file.readlines()\n",
    "    data = [line.strip().split(\",\") for line in data]\n",
    "    headers = data.pop(0)\n",
    "\n",
    "# Transform dataframe\n",
    "condicion_inicial_unidad = pd.DataFrame(data, columns=headers)\n",
    "# Generate name mappes\n",
    "condicion_inicial_map = {\n",
    "    gen: process.extractOne(\n",
    "        query=gen.lower(),\n",
    "        choices=dispo[\"resource_name\"].unique(),\n",
    "        scorer=fuzz.token_sort_ratio,\n",
    "        processor=lambda x: x.lower().replace(\" \", \"\"),\n",
    "        # score_cutoff=70,\n",
    "    )[0]\n",
    "    for gen in condicion_inicial_planta.Recurso.unique()\n",
    "}\n",
    "# FIX some maps\n",
    "condicion_inicial_map |= {\n",
    "    \"FLORES IV\": \"FLORES 4 CC\",\n",
    "    \"TSIERRA\": \"TERMOSIERRA CC\",\n",
    "    \"GUAJIR21\": \"GUAJIRA 2\",\n",
    "}\n",
    "condicion_inicial_planta[\"Recurso\"] = condicion_inicial_planta[\"Recurso\"].apply(\n",
    "    lambda x: condicion_inicial_map.get(x, x)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Generating new resources for CC plants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.1. New CC resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP previous CC\n",
    "CC_MAP = {\n",
    "    gen: process.extractOne(\n",
    "        query=gen.lower(),\n",
    "        choices=dispo[\"resource_name\"].unique(),\n",
    "        scorer=fuzz.partial_token_sort_ratio,\n",
    "        processor=lambda x: x.lower().replace(\" \", \"\"),\n",
    "        score_cutoff=70,\n",
    "    )[0]\n",
    "    for gen in CC.keys()\n",
    "}\n",
    "CC_MAP\n",
    "\n",
    "dispo = dispo[~dispo[\"resource_name\"].isin(list(CC_MAP.values()))]\n",
    "ofertas = ofertas[~ofertas[\"resource_name\"].isin(list(CC_MAP.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCLUDING CC RESOURCE in DISPO and OFERTAS\n",
    "new_cc_resources = pd.DataFrame(cc_dispo).stack().reset_index()\n",
    "new_cc_resources.columns = [\"hours\", \"resource_name\", \"dispo\"]\n",
    "new_cc_resources[\"dispo\"] = new_cc_resources[\"dispo\"] * 1e3\n",
    "new_cc_resources[\"hours\"] = new_cc_resources[\"hours\"].astype(int)\n",
    "new_cc_resources[\"datetime\"] = pd.to_datetime(DISPATCH_DATE) + pd.to_timedelta(\n",
    "    new_cc_resources[\"hours\"], unit=\"h\"\n",
    ")\n",
    "new_cc_resources[\"gen_type\"] = \"TERMICA\"\n",
    "new_cc_resources[\"dispatched\"] = \"DESPACHADO CENTRALMENTE\"\n",
    "new_cc_resources[\"company_activity\"] = \"GENERACIÓN\"\n",
    "new_cc_resources.pop(\"hours\")\n",
    "\n",
    "\n",
    "# OFERTAS\n",
    "\n",
    "new_cc_bid = pd.DataFrame(cc_price, index=[1]).stack().reset_index(drop=False)\n",
    "new_cc_bid.columns = [\"index_\", \"resource_name\", \"Value\"]\n",
    "new_cc_bid[\"Value\"] = new_cc_bid[\"Value\"].apply(lambda x: x * 1e-3)\n",
    "# new_cc_bid[\"datetime\"] = pd.to_datetime(DISPATCH_DATE) + pd.to_timedelta(new_cc_bid[\"hours\"], unit=\"h\")\n",
    "new_cc_bid[\"resource_gen_type\"] = \"TERMICA\"\n",
    "new_cc_bid[\"Date\"] = DISPATCH_DATE\n",
    "# new_cc_bid[\"dispatched\"] = \"DESPACHADO CENTRALMENTE\"\n",
    "# new_cc_bid[\"company_activity\"] = \"GENERACIÓN\"\n",
    "_ = new_cc_bid.pop(\"index_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispo = pd.concat([dispo, new_cc_resources], axis=0)\n",
    "ofertas = pd.concat([ofertas, new_cc_bid], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2 Adding units for each CC resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CC_MAP_inv = {v: k for k, v in CC_MAP.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcondIniPlant = condicion_inicial_planta[\n",
    "    condicion_inicial_planta.Recurso.isin(CC_MAP.values())\n",
    "]\n",
    "dcondIniPlant.loc[:, \"Recurso\"] = dcondIniPlant[\"Recurso\"].apply(\n",
    "    lambda x: CC_MAP_inv.get(x, x)\n",
    ")\n",
    "dcondIniPlant.loc[:, \"dispatched_conf\"] = dcondIniPlant.loc[:, \"Conf_Pini-1\"].apply(\n",
    "    lambda x: int(re.findall(r\"\\d+\", x)[0])\n",
    ")\n",
    "# dcondIniPlant = dcondIniPlant[dcondIniPlant[\"dispatched_conf\"]>0]\n",
    "dcondIniPlant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_condition_df = pd.DataFrame()\n",
    "for plant, cc_plants in deepcopy(CC).items():\n",
    "    filtered_init_condition = dcondIniPlant.query(\"Recurso == @plant\").reset_index()\n",
    "    dispatched_conf = filtered_init_condition.loc[0, \"dispatched_conf\"]\n",
    "    if filtered_init_condition.loc[0, \"dispatched_conf\"] != 0:\n",
    "        filtered_init_condition.loc[0, \"Recurso\"] = f\"{plant}_{dispatched_conf}\"\n",
    "        dispatched_config = f\"{plant}_{dispatched_conf}\"\n",
    "        cc_plants.pop(cc_plants.index(dispatched_config))\n",
    "    to_concat = [filtered_init_condition for _ in cc_plants]\n",
    "    if to_concat:\n",
    "        filtered_init_condition_ = pd.concat(to_concat)\n",
    "        filtered_init_condition_[\"Recurso\"] = cc_plants\n",
    "        filtered_init_condition_[\"Gpini-1\"] = 0\n",
    "        filtered_init_condition = pd.concat(\n",
    "            [filtered_init_condition, filtered_init_condition_], ignore_index=True\n",
    "        )\n",
    "        filtered_init_condition = filtered_init_condition[\n",
    "            ~filtered_init_condition[\"Recurso\"].isin([plant])\n",
    "        ]\n",
    "    initial_condition_df = pd.concat(\n",
    "        [initial_condition_df, filtered_init_condition], ignore_index=True\n",
    "    )\n",
    "\n",
    "\n",
    "condicion_inicial_planta_termicas = condicion_inicial_planta[\n",
    "    ~(condicion_inicial_planta[\"Tipo\"] == \"H\")\n",
    "    & ~(condicion_inicial_planta[\"Recurso\"].isin(CC_MAP.values()))\n",
    "]\n",
    "initial_condition_df = pd.concat(\n",
    "    [initial_condition_df, condicion_inicial_planta_termicas], ignore_index=True\n",
    ")\n",
    "initial_condition_df = initial_condition_df.astype(\n",
    "    {\"T_CONF_Pini-1\": int, \"Gpini-1\": float}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Generating initial set to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_generators = ofertas.resource_name.unique()\n",
    "generators = dispo.resource_name.unique()\n",
    "timestamps = demanda[\"datetime\"].to_dict().values()\n",
    "# fuel_generators = dispo.query('resource_name in @major_generators and gen_type==\"TERMICA\"').resource_name.unique()\n",
    "fuel_generators = dispo[\n",
    "    (dispo[\"resource_name\"].isin(major_generators)) & (dispo[\"gen_type\"] == \"TERMICA\")\n",
    "].resource_name.unique()\n",
    "\n",
    "\n",
    "# Thermal gen\n",
    "gen_on = initial_condition_df[initial_condition_df[\"Gpini-1\"] != 0][\"Recurso\"].unique()\n",
    "gen_off = list(set(fuel_generators) - set(gen_on))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7. Get startup/shutdown costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MO_map = {\n",
    "    gen: results[0]\n",
    "    for gen in minimo_operativo.resource.unique()\n",
    "    if (\n",
    "        results := process.extractOne(\n",
    "            query=gen.lower(),\n",
    "            choices=generators,\n",
    "            # choices=major_generators.tolist(),\n",
    "            scorer=fuzz.token_sort_ratio,\n",
    "            processor=lambda x: x.lower().replace(\" \", \"\"),\n",
    "            score_cutoff=70,\n",
    "        )\n",
    "    )\n",
    "}\n",
    "minimo_operativo[\"resource\"] = minimo_operativo[\"resource\"].apply(\n",
    "    lambda x: MO_map.get(x, x)\n",
    ")\n",
    "minimo_operativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generators_pap_map = {\n",
    "    gen: process.extractOne(\n",
    "        query=gen.lower(),\n",
    "        choices=precio_arranque.resource.unique(),\n",
    "        scorer=fuzz.partial_token_sort_ratio,\n",
    "        processor=lambda x: x.lower().replace(\" \", \"\"),\n",
    "        score_cutoff=70,\n",
    "    )[0]\n",
    "    for gen in fuel_generators\n",
    "}\n",
    "\n",
    "cold_start = {}\n",
    "for gen in fuel_generators:\n",
    "    gen_name_mapped = generators_pap_map[gen]\n",
    "    gen_pap = precio_arranque[\n",
    "        (precio_arranque[\"resource\"] == gen_name_mapped)\n",
    "        & (precio_arranque.type.str.contains(\"C\"))\n",
    "    ][\"price\"].values[0]\n",
    "    cold_start[gen] = float(gen_pap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores en MWh\n",
    "Pmax = (\n",
    "    dispo.query(\"resource_name in @generators\")\n",
    "    .set_index([\"resource_name\", \"datetime\"])\n",
    "    .sort_index()[\"dispo\"]\n",
    "    * 1e-3\n",
    ")\n",
    "Pmin = minimo_operativo.set_index([\"resource\", \"datetime\"]).sort_index()[\n",
    "    \"minimo_operativo\"\n",
    "]\n",
    "beta = (\n",
    "    ofertas.query(\"resource_name in @generators\")\n",
    "    .set_index([\"resource_name\"])\n",
    "    .sort_index()[\"Value\"]\n",
    "    * 1e3\n",
    ")\n",
    "agc_indexed = agc_asignado.set_index([\"recurso\", \"datetime\"])[\"agc\"] * 1e-3\n",
    "\n",
    "# Pmax.loc[agc_indexed.index] = Pmax.loc[agc_indexed.index] -  agc_indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_pronos = pd.read_csv(\n",
    "    f\"data/{DISPATCH_DATE}/PrId{DISPATCH_DATE.month:0>2}{DISPATCH_DATE.day:0>2}_NAL.txt\",\n",
    "    header=None,\n",
    "    encoding=\"latin1\",\n",
    ")\n",
    "demand_pronos = demand_pronos.iloc[:, 1:].sum().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_pronos = dict(zip(demanda[\"datetime\"], demand_pronos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ton = initial_condition_df.set_index([\"Recurso\"]).query(\"Recurso in @gen_on\")[\n",
    "    \"T_CONF_Pini-1\"\n",
    "]\n",
    "Ton = Ton[Ton.index.isin(fuel_generators)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_on_t0_minus_1 = {\n",
    "    gen: 1\n",
    "    for gen in initial_condition_df[initial_condition_df[\"Gpini-1\"] > 0][\n",
    "        \"Recurso\"\n",
    "    ].unique()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_on_t0_minus_1 = {k: v for k, v in z_on_t0_minus_1.items() if k in fuel_generators}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Fix fuel-fire generators to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_fuel_fire = pd.read_csv(\n",
    "    f\"data/{DISPATCH_DATE}/PrId{DISPATCH_DATE.month:0>2}{DISPATCH_DATE.day:0>2}_NAL.txt\",\n",
    "    header=None,\n",
    "    encoding=\"latin1\",\n",
    ")\n",
    "fixed_fuel_fire.columns = [\"generator\"] + list(range(24))\n",
    "fixed_fuel_fire = fixed_fuel_fire.set_index(\"generator\").stack().reset_index()\n",
    "fixed_fuel_fire.columns = [\"generator\", \"hour\", \"gen\"]\n",
    "fixed_fuel_fire[\"datetime\"] = pd.to_datetime(DISPATCH_DATE) + pd.to_timedelta(\n",
    "    fixed_fuel_fire[\"hour\"], unit=\"h\"\n",
    ")\n",
    "\n",
    "# Fix generation\n",
    "fixed_fuel_fired_map = {}\n",
    "for gen in fixed_fuel_fire.generator.unique():\n",
    "    # if not (\n",
    "    #     str(gen).startswith(\"AG_\") or\n",
    "    #     str(gen).startswith(\"M\") or\n",
    "    #     str(gen).startswith(\"GD\") or\n",
    "    #     str(gen).startswith(\"AR\")\n",
    "    # ):\n",
    "    choice = process.extractOne(\n",
    "        query=gen.lower(),\n",
    "        choices=generators,\n",
    "        scorer=fuzz.partial_ratio,\n",
    "        processor=lambda x: x.lower().replace(\" \", \"\"),\n",
    "        # score_cutoff=60,\n",
    "    )\n",
    "    if choice and choice[0] in generators:\n",
    "        fixed_fuel_fired_map[gen] = choice[0]\n",
    "    else:\n",
    "        ...\n",
    "        # print(f\"{gen} select {choice} but is not a fuel generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_fuel_fire_2 = fixed_fuel_fire.copy()\n",
    "with open(\"data/preideal_dispatch_map.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    preideal_dispatch_map = json.load(file)\n",
    "fixed_fuel_fire_2[\"generador_model\"] = fixed_fuel_fire_2[\"generator\"].apply(\n",
    "    lambda x: preideal_dispatch_map.get(x, \"\")\n",
    ")\n",
    "fixed_fuel_fire_2 = fixed_fuel_fire_2[\n",
    "    (fixed_fuel_fire_2[\"generador_model\"].notnull())\n",
    "    & (fixed_fuel_fire_2[\"generador_model\"] != \"\")\n",
    "    & ~(fixed_fuel_fire_2[\"generador_model\"].isin(major_generators))\n",
    "]\n",
    "fixed_fuel_fire_2 = fixed_fuel_fire_2.set_index([\"generador_model\", \"datetime\"])[\"gen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pmax_model = Pmax.apply(lambda x: np.round(x, 0)).to_dict()\n",
    "\n",
    "if \"preideal\" in config.dispatch_type:\n",
    "    Pmax_model.update(fixed_fuel_fire_2.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RAMPS ---\n",
    "with open(\"data/ramps.json\", \"r\") as file:\n",
    "    ramps = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEMANDA = (\n",
    "    demand_pronos\n",
    "    if \"preideal\" in config.dispatch_type\n",
    "    else (demanda.set_index(\"datetime\")[\"dema\"] * 1e-3).astype(int)\n",
    ")\n",
    "MAX_MIN_OP = 1 if \"preideal\" in config.dispatch_type else 0\n",
    "TMG = (\n",
    "    parametros_plantas[parametros_plantas[\"generador\"].isin(fuel_generators)]\n",
    "    .set_index(\"generador\")[\"TMG\"]\n",
    "    .astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramps = {k: v for k, v in ramps.items() if k in fuel_generators}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_data = {\n",
    "    \"G\": fuel_generators,\n",
    "    \"T\": timestamps,\n",
    "    \"I\": generators,\n",
    "    \"combined_cycle\": list(CC.keys()),\n",
    "    \"excluded_resource\": CC,\n",
    "    \"gen_on\": gen_on,\n",
    "    \"gen_off\": gen_off,\n",
    "}\n",
    "\n",
    "\n",
    "param_data = {\n",
    "    \"Pmax\": Pmax_model,\n",
    "    # \"Pmin\" : Pmin,\n",
    "    \"Pmin\": {},\n",
    "    \"beta\": beta,\n",
    "    \"cold_start\": cold_start,\n",
    "    \"demand\": DEMANDA,\n",
    "    \"Ton\": Ton,\n",
    "    \"z_on_t0_minus_1\": z_on_t0_minus_1,\n",
    "    \"TMG\": TMG,\n",
    "    \"ramp_up\": ramps,\n",
    "    \"ramp_down\": ramps,\n",
    "    \"max_min_op\": MAX_MIN_OP,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BESS = {\n",
    "    \"BESS_1\": {\n",
    "        \"MWh_nom\": 2000,\n",
    "        \"hours_to_deplete\": 2,\n",
    "        \"efficiency\": 0.9,\n",
    "        \"min_soc\": 0,\n",
    "        \"max_soc\": 1,\n",
    "        \"initial_soc\": 0.5,\n",
    "        \"charge_bid\": 1E6,\n",
    "        \"discharge_bid\": 0,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dispatch_type in [\n",
    "    DispatchOptions.bess_ideal,\n",
    "    DispatchOptions.bess_preideal,\n",
    "]:\n",
    "    set_data.update(**{\"BESS\": list(BESS.keys())})\n",
    "    BESS_PARAMS_NAMES = [\n",
    "        \"bess_soc_0\",\n",
    "        \"bess_charge_bid\",\n",
    "        \"bess_discharge_bid\",\n",
    "        \"bess_soc_bid\",\n",
    "        \"bess_min_soc\",\n",
    "        \"bess_max_soc\",\n",
    "        \"efficiency\",\n",
    "        \"bess_max_charge\",\n",
    "        \"bess_max_discharge\",\n",
    "    ]\n",
    "    bess_params_model = dict(zip(BESS_PARAMS_NAMES, [{} for _ in BESS_PARAMS_NAMES]))\n",
    "    for bess_name, bess_params in BESS.items():\n",
    "        bess_params_model[\"bess_soc_0\"].update(\n",
    "            **{bess_name: bess_params[\"initial_soc\"] * bess_params[\"MWh_nom\"]}\n",
    "        )\n",
    "        bess_params_model[\"bess_charge_bid\"].update(\n",
    "            **{bess_name: bess_params[\"charge_bid\"]}\n",
    "        )\n",
    "        bess_params_model[\"bess_discharge_bid\"].update(\n",
    "            **{bess_name: bess_params[\"discharge_bid\"]}\n",
    "        )\n",
    "        bess_params_model[\"bess_min_soc\"].update(\n",
    "            **{bess_name: bess_params[\"min_soc\"] * bess_params[\"MWh_nom\"]}\n",
    "        )\n",
    "        bess_params_model[\"bess_max_soc\"].update(\n",
    "            **{bess_name: bess_params[\"max_soc\"] * bess_params[\"MWh_nom\"]}\n",
    "        )\n",
    "        bess_params_model[\"efficiency\"].update(**{bess_name: bess_params[\"efficiency\"]})\n",
    "        bess_params_model[\"bess_max_charge\"].update(\n",
    "            **{bess_name: bess_params[\"MWh_nom\"] / bess_params[\"hours_to_deplete\"]}\n",
    "        )\n",
    "        bess_params_model[\"bess_max_discharge\"].update(\n",
    "            **{bess_name: bess_params[\"MWh_nom\"] / bess_params[\"hours_to_deplete\"]}\n",
    "        )\n",
    "\n",
    "    param_data.update(**bess_params_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bess_params_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 Solving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UnitCommitmentModel(config=config)\n",
    "model.create_model(set_data=set_data, param_data=param_data)\n",
    "\n",
    "\n",
    "# model._model.pout[\"ALBAN\",[pd.Timestamp(\"2024-04-25 18:00:00\")]].fix(388)\n",
    "# model._model.pout[\"ALBAN\",[pd.Timestamp(\"2024-04-25 19:00:00\")]].fix(388)\n",
    "# model._model.pout[\"ALBAN\",[pd.Timestamp(\"2024-04-25 20:00:00\")]].fix(353)\n",
    "\n",
    "\n",
    "# model._model.pout[\"SOGAMOSO\",[pd.Timestamp(\"2024-04-25 18:00:00\")]].fix(3)\n",
    "# model._model.pout[\"SOGAMOSO\",[pd.Timestamp(\"2024-04-25 19:00:00\")]].fix(89)\n",
    "\n",
    "\n",
    "# results = model.solve(solver=\"cplex\", executable=\"solver/cplex\")\n",
    "\n",
    "# model._model.z.fix()\n",
    "\n",
    "# results = model.solve(solver=\"cplex\", executable=\"solver/cplex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.solve(solver=\"cplex\", tee=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ===== WARNING FIXING VARIABLES =====\n",
    "# for gen, model_gen_name in fix_fuel_fired_gen_.items():\n",
    "#     # Filter data\n",
    "#     serie = fixed_fuel_fire[fixed_fuel_fire[\"generator\"]==gen]\n",
    "#     serie[\"generator\"] = model_gen_name\n",
    "#     for k,v in serie.set_index([\"generator\", \"datetime\"])[\"gen\"].to_dict().items():\n",
    "#         model._model.pout[k].fix(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in model._model.T:\n",
    "#     model._model.pout[\"TERMONORTE\",t].fix(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = model._model.objective.expr()\n",
    "print(f\"F.obj: {expr:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_up = sum(\n",
    "    model._model.cold_start[g] * model._model.zup[g, t].value\n",
    "    for g in model._model.G\n",
    "    for t in model._model.T\n",
    ")\n",
    "gen_cost = sum(\n",
    "    model._model.beta[i] * model._model.pout[i, t].value\n",
    "    for i in model._model.I\n",
    "    for t in model._model.T\n",
    ")\n",
    "\n",
    "print(f\"f.o.{start_up + gen_cost:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpo_xm = pd.read_csv(\n",
    "    f\"data/{DISPATCH_DATE}/iMAR{DISPATCH_DATE.month:0>2}{DISPATCH_DATE.day:0>2}_NAL.txt\",\n",
    "    header=None,\n",
    ")\n",
    "mpo_xm = mpo_xm.iloc[0, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPO = {\n",
    "    ke.index(): model._model.objective.sense.value * pyo.value(dual_)\n",
    "    for ke, dual_ in model._model.dual.items()\n",
    "    if \"power_balance\" in ke.name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch = {\n",
    "    (gen, date_): pyo.value(dispatch)\n",
    "    for (gen, date_), dispatch in model._model.pout.items()\n",
    "}\n",
    "dispatch = pd.DataFrame(\n",
    "    data=dispatch.values(), index=dispatch.keys(), columns=[\"dispatch\"]\n",
    ").reset_index(drop=False, names=[\"generador\", \"datetime\"])\n",
    "dispatch.to_csv(\n",
    "    f\"data/results/dispatch_by_gen-{DISPATCH_DATE}-{config.dispatch_type.value}.csv\",\n",
    "    sep=\",\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_fuel_fire = fixed_fuel_fire.rename(columns={\"gen\": \"xm_dispatch\"})\n",
    "dispatch = dispatch.rename(columns={\"dispatch\": \"udea_dispatch\"})\n",
    "error_mapper = {\n",
    "    gen: process.extractOne(\n",
    "        query=gen.lower(),\n",
    "        choices=fixed_fuel_fire[\"generator\"].unique(),\n",
    "        scorer=fuzz.partial_ratio,\n",
    "        processor=lambda x: x.lower().replace(\" \", \"\"),\n",
    "        # score_cutoff=60,\n",
    "    )[0]\n",
    "    for gen in dispatch[\"generador\"].unique()\n",
    "}\n",
    "with open(\"data/error_map.json\", \"r\") as file:\n",
    "    error_map = json.load(file)\n",
    "error_mapper |= error_map\n",
    "\n",
    "dispatch[\"generador_preideal\"] = dispatch[\"generador\"].apply(\n",
    "    lambda x: error_mapper.get(x, x)\n",
    ")\n",
    "dispatch_merged = dispatch.merge(\n",
    "    fixed_fuel_fire,\n",
    "    left_on=[\"generador_preideal\", \"datetime\"],\n",
    "    right_on=[\"generator\", \"datetime\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# --- Mask proelectrica ----\n",
    "proelec = dispatch_merged.loc[\n",
    "    dispatch_merged[\"generador\"].str.lower().str.contains(\"proelec\"), :\n",
    "]\n",
    "dispatch_merged = dispatch_merged.drop(index=proelec.index, axis=0)\n",
    "fixed_proelect = proelec.groupby(\"datetime\").agg(\n",
    "    {\n",
    "        \"generador\": \"first\",\n",
    "        \"datetime\": \"first\",\n",
    "        \"udea_dispatch\": \"sum\",\n",
    "        \"generador_preideal\": \"first\",\n",
    "        \"generator\": \"first\",\n",
    "        \"hour\": \"mean\",\n",
    "        \"xm_dispatch\": \"mean\",\n",
    "    }\n",
    ")\n",
    "\n",
    "dispatch_merged = pd.concat([dispatch_merged, fixed_proelect], axis=0)\n",
    "dispatch_merged[\"error\"] = (\n",
    "    dispatch_merged[\"udea_dispatch\"] - dispatch_merged[\"xm_dispatch\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "available_CC = list(chain(*CC.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatched_cc = initial_condition_df[\n",
    "    (initial_condition_df[\"Gpini-1\"] > 0)\n",
    "    & (initial_condition_df[\"Recurso\"].isin(available_CC))\n",
    "].Recurso.values\n",
    "delete_cc = set(available_CC) - set(dispatched_cc)\n",
    "dispatch_merged = dispatch_merged[~(dispatch_merged[\"generador\"].isin(delete_cc))]\n",
    "dispatch_merged[\"legend_group\"] = dispatch_merged[\"generador\"].apply(\n",
    "    lambda x: \"major\" if x in major_generators else \"minor\"\n",
    ")\n",
    "dispatch_merged = dispatch_merged.sort_values([\"generador\", \"datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(\n",
    "    dispatch_merged,\n",
    "    x=\"datetime\",\n",
    "    y=\"error\",\n",
    "    color=\"generador\",\n",
    "    # legendgroup=\"legend_group\",\n",
    "    title=f\"Error de despacho por generador en el {DISPATCH_DATE}\",\n",
    "    hover_data=[\"xm_dispatch\", \"udea_dispatch\"],\n",
    ")\n",
    "\n",
    "\n",
    "fig.write_html(\n",
    "    f\"data/results/error_dispatch-{DISPATCH_DATE}-{config.dispatch_type.value}.html\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "if config.dispatch_type == \"ideal\":\n",
    "    MPO_CHART = (\n",
    "        precio_bolsa.copy()\n",
    "        .set_index([\"datetime\"])\n",
    "        .rename(columns={\"precio_bolsa\": \"MPO\"})\n",
    "    )\n",
    "else:\n",
    "    MPO_CHART = pd.DataFrame(\n",
    "        data=mpo_xm, index=precio_bolsa[\"datetime\"], columns=[\"MPO\"]\n",
    "    )\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=MPO_CHART.index,\n",
    "        y=MPO_CHART[\"MPO\"],\n",
    "        mode=\"lines\",\n",
    "        name=f\"MPO {str(config.dispatch_type.value).replace('bess_','')} XM\",\n",
    "        \n",
    "    )\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=list(MPO.keys()),\n",
    "        y=list(MPO.values()),\n",
    "        mode=\"lines\",\n",
    "        name=f\"MPO {config.dispatch_type.value} Modelo\",\n",
    "        line={\"dash\": \"dash\"},\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    # title=f\"Precio Bolsa {DISPATCH_DATE}\",\n",
    "    xaxis_title=\"Hora\",\n",
    "    yaxis_title=\"Precio [COP/MWh]\",\n",
    "    width=800,\n",
    "    height=600,\n",
    "    xaxis=dict(\n",
    "        dtick=3_600_000,\n",
    "    ),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "# pd.DataFrame(data=MPO, index=[f\"MPO-{config.dispatch_type.value}\"]).T.plot(kind=\"line\",ax=ax)\n",
    "\n",
    "# if config.dispatch_type == \"ideal\":\n",
    "#     precio_bolsa.plot(kind=\"line\", x=\"datetime\", y=\"precio_bolsa\", ax=ax, linestyle='-.')\n",
    "# else:\n",
    "#     pd.DataFrame(data=mpo_xm, index=timestamps, columns=[\"MPO_XM\"]).plot(kind=\"line\", ax=ax, linestyle='--')\n",
    "\n",
    "\n",
    "# plt.show()\n",
    "# # pd.DataFrame(data=mpo_xm, index=timestamps, columns=[\"MPO_XM\"]).plot(kind=\"line\", ax=ax, linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"bess\" in config.dispatch_type.value:\n",
    "    fig = go.Figure()\n",
    "    for bess_name, bess_params in BESS.items():\n",
    "        fig.add_traces(\n",
    "            [\n",
    "                go.Bar(\n",
    "                    x=model._model.T.ordered_data(),\n",
    "                    y=[\n",
    "                        pyo.value(val)\n",
    "                        for _, val in model._model.bess_charge[\n",
    "                            bess_name, :\n",
    "                        ].expanded_items()\n",
    "                    ],\n",
    "                    # mode=\"lines\",\n",
    "                    name=f\"Charging {bess_name}\",\n",
    "                    # stackgroup=\"one\",\n",
    "                ),\n",
    "                go.Bar(\n",
    "                    x=model._model.T.ordered_data(),\n",
    "                    y=[\n",
    "                        pyo.value(val)\n",
    "                        for _, val in model._model.bess_discharge[\n",
    "                            bess_name, :\n",
    "                        ].expanded_items()\n",
    "                    ],\n",
    "                    # mode=\"lines\",\n",
    "                    name=f\"Discharging {bess_name}\",\n",
    "                    # stackgroup=\"one\",\n",
    "                ),\n",
    "                go.Scatter(\n",
    "                    x=model._model.T.ordered_data(),\n",
    "                    y=[\n",
    "                        pyo.value(val)\n",
    "                        for _, val in model._model.soc_bess[\n",
    "                            bess_name, :\n",
    "                        ].expanded_items()\n",
    "                    ],\n",
    "                    mode=\"lines\",\n",
    "                    name=f\"SOC {bess_name}\",\n",
    "                    stackgroup=\"one\",\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "        {\n",
    "            \"yaxis_title\": \"Potencia [MW]\",\n",
    "            \"xaxis_title\": \"Fecha-Hora\",\n",
    "            \"xaxis\": dict(\n",
    "                # tickformat=\"%-d-%-H\",\n",
    "                dtick=3_600_000,\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
