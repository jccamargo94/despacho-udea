{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import holidays\n",
    "from sklearn.cluster import HDBSCAN, KMeans\n",
    "import pandas as pd\n",
    "\n",
    "co_hol = holidays.Colombia()\n",
    "\n",
    "Winter = [5, 6, 7, 8, 9, 10, 11]\n",
    "Summer = [1, 2, 3, 4, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data/Generacion_(kWh)_2024.xlsx', engine='openpyxl', parse_dates=[\"Fecha\"])\n",
    "df_ = df.set_index([\n",
    "    col for col in df.columns if col not in [str(h) for h in range(24)]\n",
    "])\n",
    "df_.columns = range(24)\n",
    "df_ = df_.stack().reset_index()\n",
    "df_.rename(columns={'level_10': \"hours\", 0: \"generacion\"}, inplace=True)\n",
    "df_[\"datetime\"] = pd.to_datetime(df_[\"Fecha\"]) + pd.to_timedelta(df_[\"hours\"], unit='h')\n",
    "df_ = df.set_index([\n",
    "    col for col in df.columns if col not in [str(h) for h in range(24)]\n",
    "])\n",
    "df_.columns = range(24)\n",
    "df_ = df_.stack().reset_index()\n",
    "df_.rename(columns={'level_10': \"hours\", 0: \"generacion\"}, inplace=True)\n",
    "df_[\"datetime\"] = pd.to_datetime(df_[\"Fecha\"]) + pd.to_timedelta(df_[\"hours\"], unit='h')\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_agg = df_.groupby([\"Fecha\", \"Tipo Generación\"]).agg({\n",
    "    \"generacion\": \"sum\",\n",
    "}).reset_index()\n",
    "# }).reset_index()\n",
    "df_agg[\"generacion\"] = df_agg[\"generacion\"]*1E-6 \n",
    "df_agg = df_agg.pivot(index=\"Fecha\", columns=\"Tipo Generación\", values=\"generacion\")\n",
    "df_agg.columns.name=None\n",
    "df_agg[\"TOTAL_GEN\"] = df_agg.sum(axis=1)\n",
    "# Generación in GWh\n",
    "df_agg = df_agg.reset_index()\n",
    "\n",
    "df_agg[\"day_of_week\"] = df_agg[\"Fecha\"].dt.dayofweek\n",
    "# df_agg[\"week_of_year\"] = df_agg[\"Fecha\"].dt.isocalendar().week\n",
    "df_agg[\"winter\"] = df_agg[\"Fecha\"].dt.month.apply(lambda x:  1 if x in Winter else 0)\n",
    "# df_agg[\"is_holiday\"] = df_agg[\"Fecha\"].apply(lambda x: 1 if co_hol.get(x) else 0)\n",
    "df_agg.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Add precio bolsa to cluster ===\n",
    "precio_bolsa = pd.read_excel('data/Precio_Bolsa_Nacional_($kwh)_2024.xlsx', engine='openpyxl', parse_dates=[\"Fecha\"])\n",
    "precio_bolsa_ = precio_bolsa.set_index([\"Fecha\"]).stack().reset_index()\n",
    "precio_bolsa_.columns = [\"Fecha\", \"hours\", \"precio_bolsa\"]\n",
    "precio_bolsa_agg = precio_bolsa_.groupby([\"Fecha\"]).agg({\"precio_bolsa\":[\"max\", \"mean\", \"min\"]}).reset_index()\n",
    "precio_bolsa_agg.columns = ['_'.join(col).strip() for col in precio_bolsa_agg.columns.values]\n",
    "precio_bolsa_agg.rename(columns={\"Fecha_\": \"Fecha\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_agg.merge(precio_bolsa_agg, on=\"Fecha\", how=\"inner\")\n",
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excep_columns = [\"Fecha\", \"Tipo Generación\", \"TOTAL_GEN\", \"day_of_week\", \"winter\"]\n",
    "excep_columns = excep_columns + [\"COGENERADOR\", \"EOLICA\", \"SOLAR\"]\n",
    "\n",
    "df_agg[[col for col in df_agg.columns if col not in excep_columns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Select the columns to normalize\n",
    "columns_to_normalize = [col for col in df_agg.columns if col not in excep_columns]\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_agg_norma = df_agg.copy()\n",
    "# Fit and transform the data\n",
    "df_agg_norma[columns_to_normalize] = scaler.fit_transform(df_agg_norma[columns_to_normalize])\n",
    "\n",
    "df_agg_norma[columns_to_normalize].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit K-means for different values of k\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from scipy.spatial.distance import cdist\n",
    "\n",
    "# distortions = []\n",
    "# inertias = []\n",
    "# mapping1 = {}\n",
    "# mapping2 = {}\n",
    "\n",
    "# X = df_agg_norma[[col for col in df_agg_norma.columns if col not in excep_columns]].values\n",
    "# X = X.astype(float)\n",
    "# for k in K:\n",
    "#     kmeanModel = KMeans(n_clusters=k, random_state=42).fit(X)\n",
    "    \n",
    "#     # Calculate distortion as the average squared distance from points to their cluster centers\n",
    "#     distortions.append(sum(np.min(cdist(X, kmeanModel.cluster_centers_, 'euclidean'), axis=1)**2) / X.shape[0])\n",
    "    \n",
    "#     # Inertia is calculated directly by KMeans\n",
    "#     inertias.append(kmeanModel.inertia_)\n",
    "    \n",
    "#     # Store the mappings for easy access\n",
    "#     mapping1[k] = distortions[-1]\n",
    "#     mapping2[k] = inertias[-1]\n",
    "\n",
    "# print(\"Distortion values:\")\n",
    "# for key, val in mapping1.items():\n",
    "#     print(f'{key} : {val}')\n",
    "# # Plotting the graph of k versus Distortion\n",
    "# plt.plot(K, distortions, 'bx-')\n",
    "# plt.xlabel('Número de clusters (k)')\n",
    "# plt.ylabel('Distorsión')\n",
    "# plt.xticks(K)  # Set x-axis ticks as integer numbers\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusterer = HDBSCAN()\n",
    "clusterer = KMeans(n_clusters=7, random_state=2747364364)\n",
    "clusterer.fit(X=df_agg_norma[[col for col in df_agg_norma.columns if col not in excep_columns]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg[\"cluster\"] = [f\"cluster_{int(cluster)+1}\"for cluster in clusterer.labels_]\n",
    "df_agg[\"day_name\"] = df_agg[\"Fecha\"].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.cluster.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"\")\n",
    "\n",
    "df_agg.groupby(\"cluster\").agg({\"Fecha\": lambda x : list(x)}).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.groupby(\"cluster\").agg({\"Fecha\": \"count\"}).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    data_frame=df_agg,\n",
    "    x=\"Fecha\",\n",
    "    y=\"TOTAL_GEN\",\n",
    "    color=\"cluster\",\n",
    "    color_discrete_sequence=px.colors.qualitative.Set1,\n",
    "    # hover_data=[\"week_of_year\", \"day_of_week\", \"is_holiday\", \"day_name\"],\n",
    ")\n",
    "fig.add_traces(\n",
    "    [\n",
    "        go.Scatter(\n",
    "            x=df_agg[\"Fecha\"],\n",
    "            y=df_agg[\"TERMICA\"],\n",
    "            mode='lines',\n",
    "            line=dict(color='black', width=1),\n",
    "            name=\"Termica\",\n",
    "        ),\n",
    "        go.Scatter(\n",
    "            x=df_agg[\"Fecha\"],\n",
    "            y=df_agg[\"HIDRAULICA\"],\n",
    "            mode='lines',\n",
    "            line=dict(color='black', width=1, dash='dash'),\n",
    "            name=\"hidro\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    data_frame=df_agg.sort_values(\"cluster\"),\n",
    "    y=\"HIDRAULICA\",\n",
    "    x=\"TERMICA\",\n",
    "    color=\"cluster\",\n",
    "    size=\"precio_bolsa_mean\",\n",
    "    color_discrete_sequence=px.colors.qualitative.Plotly,\n",
    "    hover_data=[\"day_of_week\", \"day_name\", \"Fecha\"],\n",
    ")\n",
    "fig.update_layout(\n",
    "    {\n",
    "        \"xaxis_title\": \"Generación Térmica (GWh)\",\n",
    "        \"yaxis_title\": \"Generación Hidraúlica(GWh)\",\n",
    "        \"width\": 800,\n",
    "\n",
    "}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_11 = df_agg.query(\"Fecha <= '2024-10-30'\")\n",
    "\n",
    "centers = pd.DataFrame(\n",
    "    data=clusterer.cluster_centers_,\n",
    "    columns=[col for col in df_agg_11.columns if col not in excep_columns + [\"cluster\", \"day_name\"]],\n",
    "    index=range(1,clusterer.n_clusters + 1)\n",
    ")\n",
    "centers\n",
    "df_agg_11[\"HIDRO_ERROR\"] = df_agg_11.apply(\n",
    "    lambda x: (x[\"HIDRAULICA\"] - centers.loc[int(x[\"cluster\"].split(\"_\")[1]), \"HIDRAULICA\"])**2, axis=1\n",
    ")\n",
    "df_agg_11[\"TERMICA_ERROR\"] = df_agg_11.apply(\n",
    "    lambda x: (x[\"TERMICA\"] - centers.loc[int(x[\"cluster\"].split(\"_\")[1]), \"TERMICA\"])**2, axis=1\n",
    ")\n",
    "df_agg_11[\"TOTAL_ERROR\"] = df_agg_11[\"HIDRO_ERROR\"] + df_agg_11[\"TERMICA_ERROR\"]\n",
    "min_error_dates = df_agg_11.loc[df_agg_11.groupby(\"cluster\")[\"TOTAL_ERROR\"].idxmin(), [\"cluster\", \"Fecha\", \"TOTAL_ERROR\"]]\n",
    "min_error_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
